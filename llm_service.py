import json
import logging
import os
from datetime import datetime
from openai import OpenAI

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)

class LLMParser:
    def __init__(self, api_key=None, base_url=None, model=None):
        self.api_key = api_key
        self.base_url = base_url
        self.model = model or "gpt-3.5-turbo" # Default fallback, user can change to deepseek-chat etc.
        self.client = None
        
        if self.api_key:
            try:
                self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)
                logging.info(f"ğŸ§  LLM Client initialized (Model: {self.model})")
            except Exception as e:
                logging.error(f"âŒ LLM Init failed: {e}")

    def parse(self, text, context_user="unknown"):
        """
        è§£æç”¨æˆ·æŒ‡ä»¤ï¼Œè¿”å›ç»“æ„åŒ– JSON
        """
        # 1. å¦‚æœæ²¡æœ‰ LLM å®¢æˆ·ç«¯ï¼Œè¿”å› None (è®©è°ƒç”¨è€…å›é€€åˆ°æ­£åˆ™)
        if not self.client:
            logging.warning("âš ï¸ No LLM Client active. Fallback to Regex.")
            return None

        # 2. æ„å»º Prompt
        current_date = datetime.now().strftime("%Y-%m-%d")
        
        system_prompt = f"""
You are a smart project assistant for a Feishu/Lark bot.
Current Date: {current_date}
Current User: {context_user}

Your goal is to classify the user's intent and extract entities into JSON.

### Intents (Actions):
1. "create": Create a new task.
2. "query": Query/List tasks.
3. "update_status": Update a task's status (e.g. mark as done).
4. "unknown": Cannot understand.

### Output Schema (JSON):
{{
  "action": "create" | "query" | "update_status" | "unknown",
  "params": {{
    "task_name": "string (for create)",
    "quadrant": "é‡è¦ä¸”ç´§æ€¥" | "é‡è¦ä¸ç´§æ€¥" | "ç´§æ€¥ä¸é‡è¦" | "ä¸é‡è¦ä¸ç´§æ€¥" (Infer from context. Default: "é‡è¦ä¸ç´§æ€¥"),
    "due_date": "YYYY-MM-DD",
    "owners": ["name1"],
    "keyword": "string",
    "target_status": "å·²å®Œæˆ" | "å¾…åŠ" | "è¿›è¡Œä¸­"
  }}
}}

### Matrix Logic (Eisenhower):
- **é‡è¦ä¸”ç´§æ€¥**: Critical bugs, deadlines today/tomorrow, boss requests, server down.
- **é‡è¦ä¸ç´§æ€¥**: New features, long-term plans, refactoring, learning.
- **ç´§æ€¥ä¸é‡è¦**: Meetings, interruptions, minor emails, helping others with small tasks.
- **ä¸é‡è¦ä¸ç´§æ€¥**: Browsing news, trivial tasks.

### Examples:
User: "æœåŠ¡å™¨ç‚¸äº†ï¼å¿«ä¿®ï¼"
JSON: {{"action": "create", "params": {{"task_name": "ä¿®å¤æœåŠ¡å™¨æ•…éšœ", "quadrant": "é‡è¦ä¸”ç´§æ€¥"}}}}

User: "ä¸‹ä¸ªå­£åº¦æˆ‘ä»¬è¦è§„åˆ’ä¸€ä¸‹æ–°çš„æ¶æ„"
JSON: {{"action": "create", "params": {{"task_name": "è§„åˆ’æ–°æ¶æ„", "quadrant": "é‡è¦ä¸ç´§æ€¥"}}}}

User: "å¸®æˆ‘æ‹¿ä¸€ä¸‹å¿«é€’"
JSON: {{"action": "create", "params": {{"task_name": "æ‹¿å¿«é€’", "quadrant": "ç´§æ€¥ä¸é‡è¦"}}}}
"""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": text}
                ],
                response_format={"type": "json_object"}, # Require JSON mode if supported
                temperature=0.1
            )
            content = response.choices[0].message.content
            result = json.loads(content)
            logging.info(f"ğŸ§  LLM Analysis: {result}")
            return result
        
        except Exception as e:
            logging.error(f"âŒ LLM Inference Error: {e}")
            return None
