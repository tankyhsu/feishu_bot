import json
import logging
import os
from datetime import datetime
from openai import OpenAI

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)

class LLMParser:
    def __init__(self, api_key=None, base_url=None, model=None):
        self.api_key = api_key
        self.base_url = base_url
        self.model = model or "gpt-3.5-turbo" # Default fallback, user can change to deepseek-chat etc.
        self.client = None
        
        if self.api_key:
            try:
                self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)
                logging.info(f"ğŸ§  LLM Client initialized (Model: {self.model})")
            except Exception as e:
                logging.error(f"âŒ LLM Init failed: {e}")

    def parse(self, text, context_user="unknown"):
        """
        è§£æç”¨æˆ·æŒ‡ä»¤ï¼Œè¿”å›ç»“æ„åŒ– JSON
        """
        # 1. å¦‚æœæ²¡æœ‰ LLM å®¢æˆ·ç«¯ï¼Œè¿”å› None (è®©è°ƒç”¨è€…å›é€€åˆ°æ­£åˆ™)
        if not self.client:
            logging.warning("âš ï¸ No LLM Client active. Fallback to Regex.")
            return None

        # 2. æ„å»º Prompt
        current_date = datetime.now().strftime("%Y-%m-%d")
        
        system_prompt = f"""
Role: Feishu Bot. Date: {current_date}. User: {context_user}.
Task: Extract intent & entities into JSON.

### Schema:
{{
  "action": "create"|"query"|"update_status"|"unknown",
  "params": {{
    "task_name": "string (Keep URLs/Links)",
    "quadrant": "é‡è¦ä¸”ç´§æ€¥"|"é‡è¦ä¸ç´§æ€¥"|"ç´§æ€¥ä¸é‡è¦"|"ä¸é‡è¦ä¸ç´§æ€¥" (Eisenhower Matrix, Default: "é‡è¦ä¸ç´§æ€¥"),
    "due_date": "YYYY-MM-DD",
    "owners": ["name"],
    "keyword": "string",
    "target_status": "å·²å®Œæˆ"
  }}
}}

### Examples:
U: "Server down! Fix it!" -> {{"action": "create", "params": {{"task_name": "Fix server", "quadrant": "é‡è¦ä¸”ç´§æ€¥"}}}}
U: "Read this https://bit.ly/3x" -> {{"action": "create", "params": {{"task_name": "Read this https://bit.ly/3x", "quadrant": "é‡è¦ä¸ç´§æ€¥"}}}}
U: "Done with bug fix" -> {{"action": "update_status", "params": {{"keyword": "bug fix", "target_status": "å·²å®Œæˆ"}}}}
"""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": text}
                ],
                response_format={"type": "json_object"}, # Require JSON mode if supported
                temperature=0.1
            )
            content = response.choices[0].message.content
            result = json.loads(content)
            logging.info(f"ğŸ§  LLM Analysis: {result}")
            return result
        
        except Exception as e:
            logging.error(f"âŒ LLM Inference Error: {e}")
            return None
