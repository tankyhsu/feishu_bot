import json
import re
import requests
from urllib.parse import urlparse
import lark_oapi as lark
from lark_oapi.api.minutes.v1.model import *
from openai import OpenAI

# Load Config
try:
    with open("config.json", "r") as f:
        config = json.load(f)
except:
    print("âŒ æ‰¾ä¸åˆ° config.json")
    exit(1)

APP_ID = config["APP_ID"]
APP_SECRET = config["APP_SECRET"]
LLM_API_KEY = config.get("LLM_API_KEY")
LLM_BASE_URL = config.get("LLM_BASE_URL", "https://api.deepseek.com")
LLM_MODEL = config.get("LLM_MODEL", "deepseek-chat")

# Init Client
client = lark.Client.builder() \
    .app_id(APP_ID) \
    .app_secret(APP_SECRET) \
    .log_level(lark.LogLevel.INFO) \
    .build()

llm_client = OpenAI(api_key=LLM_API_KEY, base_url=LLM_BASE_URL)

def extract_token(url):
    """
    ä»é“¾æ¥æå– token
    https://meetings.feishu.cn/minutes/obcnxyz123... -> obcnxyz123
    """
    # ç®€å•æ­£åˆ™åŒ¹é…
    match = re.search(r"/minutes/([a-zA-Z0-9]+)", url)
    if match:
        return match.group(1)
    return None

def get_minutes_text(minute_token):
    print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½å¦™è®°å­—å¹• (Token: {minute_token})...")
    
    # ä½¿ç”¨ requests ç›´æ¥è°ƒç”¨ (SDK æœ‰æ—¶å‚æ•°è¾ƒå¤šï¼Œç›´æ¥è°ƒ REST API æ›´ç›´è§‚)
    # 1. è·å– Tenant Token
    token_resp = requests.post(
        "https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal",
        json={"app_id": APP_ID, "app_secret": APP_SECRET}
    )
    tenant_token = token_resp.json().get("tenant_access_token")
    
    # 2. è·å–å­—å¹•
    # API: GET /open-apis/minutes/v1/minutes/{minute_token}/subtitle
    url = f"https://open.feishu.cn/open-apis/minutes/v1/minutes/{minute_token}/subtitle"
    headers = {"Authorization": f"Bearer {tenant_token}"}
    params = {"size": 5000} # è·å–å°½é‡å¤š
    
    resp = requests.get(url, headers=headers, params=params)
    
    if resp.status_code != 200:
        print(f"âŒ è·å–å­—å¹•å¤±è´¥: {resp.text}")
        if resp.status_code == 403:
            print("ğŸ‘‰ è¯·ç¡®ä¿ï¼š1. æœºå™¨äººå¼€é€šäº†'æŸ¥çœ‹å¦™è®°'æƒé™å¹¶å‘å¸ƒã€‚ 2. æ‚¨å·²å°†è¯¥å¦™è®°'åˆ†äº«'ç»™æœºå™¨äºº(è®¾ç½®ä¸ºå¯é˜…è¯»)ã€‚")
        return None
        
    data = resp.json().get("data", {})
    sentences = data.get("list", [])
    
    full_text = []
    for s in sentences:
        content = s.get("content", "")
        full_text.append(content)
        
    return "\n".join(full_text)

def summarize_with_ai(text):
    print("ğŸ§  æ­£åœ¨è¿›è¡Œ AI æ€»ç»“ (DeepSeek)...")
    
    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¼šè®®çºªè¦æ•´ç†åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¼šè®®å½•éŸ³è½¬æ–‡å­—å†…å®¹ï¼Œæ•´ç†å‡ºä¸€ä»½ç»“æ„æ¸…æ™°çš„çºªè¦ã€‚

å†…å®¹å¦‚ä¸‹ï¼š
{text[:8000]} 
(æ³¨ï¼šå¦‚æœå†…å®¹è¿‡é•¿å·²æˆªæ–­)

è¯·è¾“å‡º Markdown æ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š
1. **ğŸ“Œ æ ¸å¿ƒç»“è®º**: ä¸€å¥è¯æ¦‚æ‹¬ä¼šè®®è¾¾æˆçš„å…±è¯†ã€‚
2. **ğŸ“ å…³é”®ä¿¡æ¯**: 3-5ç‚¹é‡è¦çš„è®¨è®ºç»†èŠ‚ã€‚
3. **âœ… å¾…åŠäº‹é¡¹**: å…·ä½“çš„ Action Items (å¦‚æœ‰è´Ÿè´£äººè¯·æ ‡æ³¨)ã€‚
4. **ğŸ·ï¸ æ™ºèƒ½æ ‡ç­¾**: ç»™å‡º3ä¸ªåˆ†ç±»æ ‡ç­¾ï¼ˆå¦‚ #äº§å“è¯„å®¡ #Bugä¿®å¤ï¼‰ã€‚

é£æ ¼è¦æ±‚ï¼šç®€æ´ã€å•†åŠ¡ã€ä¸“ä¸šã€‚
"""

    try:
        response = llm_client.chat.completions.create(
            model=LLM_MODEL,
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âŒ AI æ€»ç»“å¤±è´¥: {e}"

if __name__ == "__main__":
    print("ğŸ”— è¯·è¾“å…¥é£ä¹¦å¦™è®°é“¾æ¥ (ä¾‹å¦‚ https://meetings.feishu.cn/minutes/obcn...):")
    url = input("> ").strip()
    
    token = extract_token(url)
    if not token:
        print("âŒ æ— æ³•è¯†åˆ«é“¾æ¥ä¸­çš„ token")
        exit(1)
        
    text = get_minutes_text(token)
    if text:
        print(f"âœ… è·å–æˆåŠŸ (å­—æ•°: {len(text)})")
        summary = summarize_with_ai(text)
        print("\n" + "="*30)
        print("ğŸ“„ ä¼šè®®çºªè¦ç”Ÿæˆç»“æœ")
        print("="*30 + "\n")
        print(summary)
